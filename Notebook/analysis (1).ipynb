{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1caceb8e",
   "metadata": {
    "id": "1caceb8e"
   },
   "source": [
    "> **Project Title:**  Recommendation System Analysis and Modelling<br>\n",
    "> **Project Owner:** Berlinda Anaman<br>\n",
    "> **Email:** Berlana.d@gmail.com<br>\n",
    "> **Github Profile:** [Berlinda Anaman](https://github.com/Berl-cloud)<br>\n",
    "> **LinkedIn Profile:** [Berlinda Anaman](https://www.linkedin.com/in/berlinda-anaman/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8b984",
   "metadata": {
    "id": "1aa8b984"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7bc47",
   "metadata": {
    "id": "dbb7bc47"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098783eb",
   "metadata": {
    "id": "098783eb",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Table of Contents<a id='mu'></a>\n",
    "\n",
    "* [Business Problem Understanding](#bpu)\n",
    "    * [Problem Statement](#ps)\n",
    "    * [Hypothesis](#hs)\n",
    "    * [Project Goal](#pg)\n",
    "    * [Information Needed](#in)\n",
    "    * [Methodology](#my)\n",
    "* [Data Preparation](#dp)\n",
    "    * [Data Quality Assessment](#dqa)\n",
    "    * [Data Cleaning and Preprocessing](#dcp)\n",
    "* [Exploratory Data Analysis](#eda)\n",
    "* [Statistical Analysis](#sa)\n",
    "    * [Removing Outliers](#ro)\n",
    "    * [Hypothesis Test](#ht)\n",
    "* [Modeling and Evaluation](#dm)\n",
    "    * [Data Understanding](#du)\n",
    "        * [Descriptive Statistics](#ds)\n",
    "        * [Data Visualization](#dv)\n",
    "    * [Feature Engineering and Selection](#fes)\n",
    "    * [Splitting Dataset](#sd)\n",
    "    * [Hyperparameter Tuning](#pt)\n",
    "    * [Finalizing Model](#fm)\n",
    "    * [Model Understanding](#mu)\n",
    "    * [Save Model](#sm)\n",
    "* [Conclusion and Recommendation](#cr)\n",
    "* [References](#r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def28cc",
   "metadata": {
    "id": "6def28cc"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8015d14f",
   "metadata": {
    "id": "8015d14f"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38baa176",
   "metadata": {
    "id": "38baa176"
   },
   "source": [
    "## 1. Business Problem Understanding<a id='bpu'></a>\n",
    "\n",
    "[Move Up](#mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095fc83",
   "metadata": {
    "id": "a095fc83"
   },
   "source": [
    "<p style=\"text-align:justify;\">The first step in approaching a data analytics problem is problem understanding. This step is very important since it allows us to know the kind of decisions we want to make, the information or data that will be needed to inform those decisions and finally, the kind of analysis that will be used to arrive at those decisions. In a nutshell, developing a mental model of the problem allows us to properly structure potentially relevant information needed to solve the problem.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52af2d2",
   "metadata": {
    "id": "c52af2d2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5797ff75",
   "metadata": {
    "id": "5797ff75"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06a216c7",
   "metadata": {
    "id": "06a216c7"
   },
   "source": [
    "## 1. Problem Statement <a id='ps'></a>\n",
    "\n",
    "The rapid growth of digital platforms has led to an overwhelming amount of available content. Users often struggle to discover relevant items that align with their preferences, resulting in lower engagement and satisfaction. Businesses, in turn, face challenges in delivering personalized recommendations that keep users active and loyal.\n",
    "The problem is to design and model a recommendation system that predicts user preferences and provides accurate, personalized suggestions, thereby improving user experience and business outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9942bd0",
   "metadata": {
    "id": "b9942bd0"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "787eed74",
   "metadata": {
    "id": "787eed74"
   },
   "source": [
    "### 1.1 Hypothesis <a id='hs'></a>\n",
    "\n",
    "- Users with similar historical behavior will likely interact with similar items.\n",
    "\n",
    "- Item similarity (e.g., category, properties) can be leveraged to make meaningful recommendations.\n",
    "\n",
    "- Increasing personalization will lead to measurable improvements in user engagement metrics such as click-through rates and repeat interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7f0eae",
   "metadata": {
    "id": "ab7f0eae"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4e2b2c6",
   "metadata": {
    "id": "e4e2b2c6"
   },
   "source": [
    "### 1.2 Project Goal <a id='pg'></a>\n",
    "\n",
    "The goal of this project is to analyze an e-commerce data to:\n",
    "\n",
    "- Develop a recommendation system that provides personalized suggestions based on user behavior and interactions.\n",
    "\n",
    "- Utilize historical user data to make accurate predictions.\n",
    "\n",
    "- Enhance user engagement and satisfaction with relevant recommendations.\n",
    "\n",
    "- Increase business metrics like sales and conversion rates through personalization.\n",
    "\n",
    "- Ensure the system is scalable and performs in real-time with large datasets.\n",
    "\n",
    "- Balance the accuracy and diversity of recommendations to avoid monotony.\n",
    "\n",
    "- Create an algorithm to predict item properties in \"addtocart\" events using \"view\" event data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c794d",
   "metadata": {
    "id": "1d5c794d"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1639d9e7",
   "metadata": {
    "id": "1639d9e7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e820a92",
   "metadata": {
    "id": "1e820a92"
   },
   "source": [
    "### 1.3 Information Needed <a id='in'></a>\n",
    "\n",
    "To successfully carry out this project, we need:\n",
    "\n",
    "- Behavior Data: This data should contain the user's interaction details. The user's time of visit, clicks, items viewed, added to cart or bought.\n",
    "- Item Properties Data: This data should include information about the items available, their various categories and availability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c8cb1e",
   "metadata": {
    "id": "90c8cb1e"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2b45c1c",
   "metadata": {
    "id": "b2b45c1c"
   },
   "source": [
    "### 1.4 Methodology <a id='my'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190b168",
   "metadata": {
    "id": "1190b168"
   },
   "source": [
    "This project will follow the **CRISP-DM (Cross-Industry Standard Process for Data Mining) framework**. This involves several detailed stages:\n",
    "\n",
    "1.  **Business Understanding:**\n",
    "    * Develop a business problem and at least seven analytical questions for the project.\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "2.  **Data Understanding and Preprocessing:**\n",
    "    * Read and understand the dataset documentation to properly comprehend the data.\n",
    "    * Handle large datasets, clean the data, and perform extensive feature engineering.\n",
    "    * Identify and remove abnormal users to improve the recommendation system's efficiency.\n",
    "\n",
    "    <br>\n",
    "\n",
    "3.  **Modeling and Evaluation:**\n",
    "    * Develop the recommendation system using appropriate machine learning techniques.\n",
    "    * Create an algorithm to predict item properties in \"addtocart\" events using \"view\" event data.\n",
    "    * Build a model to identify abnormal users in the e-commerce data.\n",
    "    * Develop a metric to evaluate the quality of the model.\n",
    "    * Evaluate the performance of the recommendation system models.\n",
    "\n",
    "    <br>\n",
    "\n",
    "4.  **Deployment (Communication of Results):**\n",
    "    * Develop appropriate visualizations to communicate insights and answer business questions.\n",
    "    * Provide comprehensive conclusions with actionable solutions based on the analysis.\n",
    "    * Create a presentation that highlights the business questions, methodology, results, and key insights.\n",
    "    * Write comprehensive documentation in a `README` file that makes the project reproducible and easy to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1319097a",
   "metadata": {
    "id": "1319097a"
   },
   "source": [
    "<p style=\"text-align:justify;\">The methodology that will be used for our project will largely depend on the goals we set out to achieve. The methodlogy framework below gives us a comprehensive guide on the methodology apparoach that will help us achieve our goals.</p>\n",
    "<br>\n",
    "<p style=\"text-align:center;font-weight:bold;font-size:20px\"> Methodology Framework</p>\n",
    "<br>\n",
    "<img src='https://artofdatablog.files.wordpress.com/2017/10/methodology-map.jpg' style=\"float:center;width:700px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35fb7e",
   "metadata": {
    "id": "1f35fb7e"
   },
   "source": [
    "Based on the methodology framework above, the methodology for this project would be guided by the type of business problem being addressed.\n",
    "\n",
    "### Business Problem\n",
    "The project has two main business problems to solve:\n",
    "1.  **Developing a recommendation system:** This involves predicting which items a user will like or interact with.\n",
    "2.  **Identifying abnormal users:** This is a classification problem, where users are categorized as either \"normal\" or \"abnormal.\"\n",
    "\n",
    "### Predicting Outcome\n",
    "For the recommendation system, we are looking at **predicting an outcome** based on **data-rich** information, specifically user behavior and item properties. For the modeling phase, we will address two distinct problems that fall under the \"Predict Outcome\" category:\n",
    "\n",
    "**1. Predicting Item Properties for \"Add to Cart\" Events**\n",
    "This is a non-binary classification problem. The goal is to predict the specific properties of an item that a user adds to their cart, based on their \"view\" events. The outcome isn't a simple yes/no, but rather a prediction from a set of possible property values. Appropriate models from the image for this task include:\n",
    "- Forest Model\n",
    "- Boosted Model\n",
    "\n",
    "**2. Identifying Abnormal Users**\n",
    "This is a binary classification problem. The goal is to classify a user as either \"normal\" or \"abnormal\". The outcome is a binary choice: the user is either one or the other. This type of analysis is crucial for data cleaning and improving the effectiveness of the recommendation system. Models suitable for this task include:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "\n",
    "### Data Analysis\n",
    "The project also involves **Data Analysis**, which includes understanding the data, finding insights, and preparing it for the models.\n",
    "* **Segmentation:** You can segment users based on their behavior (e.g., frequent shoppers vs. occasional browsers) or items based on their properties or categories.\n",
    "* **Descriptive Analysis:** This will be used to understand the dataset, such as the total number of unique visitors, event types, and items. This includes summarizing key statistics and creating initial visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec901e",
   "metadata": {
    "id": "baec901e"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abe0e125",
   "metadata": {
    "id": "abe0e125"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8e72e37",
   "metadata": {
    "id": "e8e72e37"
   },
   "source": [
    "## 2. Data Preparation <a id='dp'></a>\n",
    "\n",
    "[Move Up](#mu)\n",
    "\n",
    "An understanding of the data coupled with problem understanding will help us in cleaning and preparing our data for analysis. It is usually rare to acquire a ready-to-use data for any analysis without some level of preparation. To prepare our data, we normally assess the quality of the data, cleanse, format, blend and sample the data since we may encounter various issues with columns in our data. These issues may include:\n",
    "\n",
    "* **`Missing values:`** meaning column values are incomplete\n",
    "* **`Incorrect data:`** meaning you see values not expected for the column name\n",
    "* **`Inconsistent values:`** meaning some values may fall outside the expected range\n",
    "* **`Duplicate values:`** meaning whether or not there are duplicate values\n",
    "* **`Inconsistent data type:`** meaning values entered in the columns may not be consistent with the column names\n",
    "\n",
    "To properly prepare our data for analysis, we will perform two important tasks which are;\n",
    "\n",
    "* Part I: Data Quality Assessment\n",
    "* Part II: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e94a5b",
   "metadata": {
    "id": "10e94a5b"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aedc4e47",
   "metadata": {
    "id": "aedc4e47"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b927584",
   "metadata": {
    "id": "6b927584"
   },
   "source": [
    "### 2.1 Data Quality Assessment <a id='dqa'></a>\n",
    "\n",
    "<p style=\"text-align:justify;\">The first task that we will perform under the data preparation step is initial assessment of the quality of data which will easily allow us to properly clean our data. We will use this section to write any code necesary for inspecting the dataset. Once completed, we will leave our report in the Data Quality Report Document.\n",
    "\n",
    "At the end of our inspection, we will provide a summary of all of our findings.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0Yi8YswoaEN1",
   "metadata": {
    "id": "0Yi8YswoaEN1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef6766",
   "metadata": {
    "id": "17ef6766"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64af8f37",
   "metadata": {
    "id": "64af8f37"
   },
   "source": [
    "<center><H4>Data Sample</H4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d8f980",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "69d8f980",
    "outputId": "91bc5962-ccff-44af-a726-007e0a3860a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid event  itemid  transactionid\n",
       "0  1433221332117     257597  view  355908            NaN\n",
       "1  1433224214164     992329  view  248676            NaN\n",
       "2  1433221999827     111016  view  318965            NaN\n",
       "3  1433221955914     483717  view  253185            NaN\n",
       "4  1433221337106     951259  view  367447            NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = pd.read_csv(\"../Data/events.csv\")\n",
    "event.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "022e7dcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "022e7dcf",
    "outputId": "0fb0bfb8-e495-4191-d322-74fa37d651a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoryid</th>\n",
       "      <th>parentid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1016</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>809</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1691</td>\n",
       "      <td>885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536</td>\n",
       "      <td>1691.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoryid  parentid\n",
       "0        1016     213.0\n",
       "1         809     169.0\n",
       "2         570       9.0\n",
       "3        1691     885.0\n",
       "4         536    1691.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = pd.read_csv(\"../Data/category_tree.csv\")\n",
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f79d334",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6f79d334",
    "outputId": "1290864d-1899-4262-bb6d-8f43f48b0a39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>itemid</th>\n",
       "      <th>property</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1435460400000</td>\n",
       "      <td>460429</td>\n",
       "      <td>categoryid</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1441508400000</td>\n",
       "      <td>206783</td>\n",
       "      <td>888</td>\n",
       "      <td>1116713 960601 n277.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439089200000</td>\n",
       "      <td>395014</td>\n",
       "      <td>400</td>\n",
       "      <td>n552.000 639502 n720.000 424566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1431226800000</td>\n",
       "      <td>59481</td>\n",
       "      <td>790</td>\n",
       "      <td>n15360.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1431831600000</td>\n",
       "      <td>156781</td>\n",
       "      <td>917</td>\n",
       "      <td>828513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  itemid    property                            value\n",
       "0  1435460400000  460429  categoryid                             1338\n",
       "1  1441508400000  206783         888          1116713 960601 n277.200\n",
       "2  1439089200000  395014         400  n552.000 639502 n720.000 424566\n",
       "3  1431226800000   59481         790                       n15360.000\n",
       "4  1431831600000  156781         917                           828513"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item1 = pd.read_csv(\"../Data/item_properties_part1.1.csv\")\n",
    "item1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c364311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9c364311",
    "outputId": "947da1aa-e2eb-46e3-ac0f-cca8a8398108"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>itemid</th>\n",
       "      <th>property</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433041200000</td>\n",
       "      <td>183478</td>\n",
       "      <td>561</td>\n",
       "      <td>769062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439694000000</td>\n",
       "      <td>132256</td>\n",
       "      <td>976</td>\n",
       "      <td>n26.400 1135780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1435460400000</td>\n",
       "      <td>420307</td>\n",
       "      <td>921</td>\n",
       "      <td>1149317 1257525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1431831600000</td>\n",
       "      <td>403324</td>\n",
       "      <td>917</td>\n",
       "      <td>1204143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1435460400000</td>\n",
       "      <td>230701</td>\n",
       "      <td>521</td>\n",
       "      <td>769062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  itemid property            value\n",
       "0  1433041200000  183478      561           769062\n",
       "1  1439694000000  132256      976  n26.400 1135780\n",
       "2  1435460400000  420307      921  1149317 1257525\n",
       "3  1431831600000  403324      917          1204143\n",
       "4  1435460400000  230701      521           769062"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item2 = pd.read_csv(\"../Data/item_properties_part2.csv\")\n",
    "item2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105146e",
   "metadata": {
    "id": "7105146e"
   },
   "source": [
    "<center><H4>Data Information</H4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d1539",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f75d1539",
    "outputId": "8e3f6264-983c-4d48-a30c-77d6fac6d2bc"
   },
   "outputs": [],
   "source": [
    "#data info\n",
    "\n",
    "print('events info')\n",
    "event.info()\n",
    "\n",
    "print('\\n category info')\n",
    "cat.info()\n",
    "\n",
    "print('\\n item1 info')\n",
    "item1.info()\n",
    "\n",
    "print('\\n item2 info')\n",
    "item2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ace36f",
   "metadata": {
    "id": "78ace36f"
   },
   "source": [
    "> - `event` data has `2756101` rows and `5`columns.\n",
    "> - `category_tree` data has `1669` rows and `2`columns.\n",
    "> - `item_property1` data has `10999999` rows and `4`columns.\n",
    "> - `item_property2` data has `9275903` rows and `4`columns.\n",
    "> - `item_property1` and `item_property2` have similar features and the data documentation mentions the item properties data has been divided into two so we will merge them before we proceed with our quality assessment and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9f53dc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "d9f53dc9",
    "outputId": "957b52fa-e25f-49c8-c52c-01230a0ce920",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>itemid</th>\n",
       "      <th>property</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1435460400000</td>\n",
       "      <td>460429</td>\n",
       "      <td>categoryid</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1441508400000</td>\n",
       "      <td>206783</td>\n",
       "      <td>888</td>\n",
       "      <td>1116713 960601 n277.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439089200000</td>\n",
       "      <td>395014</td>\n",
       "      <td>400</td>\n",
       "      <td>n552.000 639502 n720.000 424566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1431226800000</td>\n",
       "      <td>59481</td>\n",
       "      <td>790</td>\n",
       "      <td>n15360.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1431831600000</td>\n",
       "      <td>156781</td>\n",
       "      <td>917</td>\n",
       "      <td>828513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  itemid    property                            value\n",
       "0  1435460400000  460429  categoryid                             1338\n",
       "1  1441508400000  206783         888          1116713 960601 n277.200\n",
       "2  1439089200000  395014         400  n552.000 639502 n720.000 424566\n",
       "3  1431226800000   59481         790                       n15360.000\n",
       "4  1431831600000  156781         917                           828513"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging item1 and item2 data\n",
    "\n",
    "items = pd.concat([item1, item2], ignore_index=True)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9abe0dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9abe0dd",
    "outputId": "e24a1e35-02fb-492e-a794-451200377c42",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99fdb82",
   "metadata": {
    "id": "c99fdb82"
   },
   "source": [
    "> The merged item data has `20275902` rows and `4` columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d2cfa",
   "metadata": {
    "id": "136d2cfa"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0713636",
   "metadata": {
    "id": "d0713636"
   },
   "source": [
    "<center><H4>Basic Statistics</H4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525253db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "525253db",
    "outputId": "ea25d075-26d1-4789-8860-717ce6a9df78"
   },
   "outputs": [],
   "source": [
    "# Inspect summary statistics\n",
    "\n",
    "print('\\n events statistics')\n",
    "display(event.describe(include='all'))\n",
    "\n",
    "print('\\n category statistics')\n",
    "display(cat.describe(include='all'))\n",
    "\n",
    "print('\\n items properties statistics')\n",
    "display(items.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa8121",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "1efa8121",
    "outputId": "66fdb5db-dd03-4778-c8d8-d152b1596df2"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "print('\\n event duplicates:')\n",
    "display(event.duplicated().sum())\n",
    "\n",
    "print('\\n category duplicates:')\n",
    "display(cat.duplicated().sum())\n",
    "\n",
    "print('\\n item properties duplicates:')\n",
    "display(items.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90257d69",
   "metadata": {
    "id": "90257d69"
   },
   "source": [
    "> `event` has 460 duplicates but `category` and `items` have no duplicate values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92bb13",
   "metadata": {
    "id": "3e92bb13"
   },
   "source": [
    "##### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53286eaa",
   "metadata": {
    "id": "53286eaa"
   },
   "outputs": [],
   "source": [
    "def missing_values(data):\n",
    "    \"\"\"\n",
    "    Calculates the total and percentage of missing values for each column in a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with 'Total' and 'Percentage' columns showing the count and\n",
    "        percentage of missing values for each column in the input DataFrame.\n",
    "    \"\"\"\n",
    "    total_missing = data.isnull().sum().sort_values(ascending=False)\n",
    "    percentage_missing = (total_missing / len(data)) * 100\n",
    "    missing_data = pd.DataFrame({'Total': total_missing, 'Percentage': percentage_missing})\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644aad2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "7644aad2",
    "outputId": "89e39974-5c84-42b1-c326-c111c55e90b2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify and quantify missing values\n",
    "\n",
    "print('\\n event missing values:')\n",
    "display(missing_values(event))\n",
    "\n",
    "print('\\n category missing values:')\n",
    "display(missing_values(cat))\n",
    "\n",
    "print('\\n items properties missing values:')\n",
    "display(missing_values(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e724b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f04e724b",
    "outputId": "347676cf-0679-4b9b-8ed7-c3a047d78cf5"
   },
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(event.isnull(), cbar=False).set_title('Missing values in events')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cat.isnull(), cbar=False).set_title('Missing values in category_tree')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(items.isnull(), cbar=False).set_title('Missing values in item_properties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6acfbfe",
   "metadata": {
    "id": "b6acfbfe"
   },
   "source": [
    "> The above ouput makes it clear that:\n",
    "> - `transactionid` column of `event` data has `2733644` missing values which forms `99.2%` of the data.\n",
    "> - `parentid\t` column of `category_tree` data has `25` missing values which forms only `1.5%` of the data.\n",
    "> - `item` has no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b93f6a",
   "metadata": {
    "id": "49b93f6a"
   },
   "source": [
    "**Checking if all items in events data exists in item properties data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34666b4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34666b4c",
    "outputId": "48ab8468-5072-4a84-99b4-39a699904ce1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_items = set(event['itemid'].unique()) - set(items['itemid'].unique())\n",
    "print(f\"Missing items from items table: {len(missing_items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299ac53",
   "metadata": {
    "id": "c299ac53"
   },
   "source": [
    "> This implies that there are `49815` unique items that do not exist in the item properties table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02e55c",
   "metadata": {
    "id": "5e02e55c"
   },
   "source": [
    "**Checking categoryid relationships**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25fdba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "0c25fdba",
    "outputId": "4827c710-b310-47a1-921c-3bfacf3f47aa"
   },
   "outputs": [],
   "source": [
    "item_categories = items[items['property'] == 'categoryid']['value'].astype(int)\n",
    "item_categories.isin(cat['categoryid']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a35da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d93a35da",
    "outputId": "55558643-6182-4780-b469-7d48e7eb8e54"
   },
   "outputs": [],
   "source": [
    "unmatched_cats = item_categories[~item_categories.isin(cat['categoryid'])]\n",
    "\n",
    "unique_unmatched_cats = unmatched_cats.nunique()\n",
    "\n",
    "print(f\"Unique unmatched categories in category table: {unique_unmatched_cats}\")\n",
    "\n",
    "print(\"List of unique unmatched categories:\", unmatched_cats.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe195d",
   "metadata": {
    "id": "dfbe195d"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff02c707",
   "metadata": {
    "id": "ff02c707"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d09f571",
   "metadata": {
    "id": "7d09f571"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74958867",
   "metadata": {
    "id": "74958867"
   },
   "source": [
    "### Data Quality Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e50f19",
   "metadata": {
    "id": "03e50f19"
   },
   "source": [
    "<p style=\"text-align:justify;\">Based on the data quality assessment, here are the key issues we identified:</p>\n",
    "\n",
    "  1. **`event`** data has 460 duplicates and it's **`transactionid`** column has **`2733644`** missing values which forms **`99.2%`** of the data. The missing values indicates that there was no transaction for such cases.\n",
    "  \n",
    "  2. **`category_tree`** data has no duplicate values but it's **`parentid`** column has **`25`** missing values which forms only **`1.5%`** of the data. The missing values indicates these are root categories  without a parent in the tree.\n",
    "  \n",
    "  3. **`items`** data has no duplicates or missing values.\n",
    "  4. The **`timestamp`** column for both **`event`** and **`items`** data has interger data type and needs to be converted to a datetime object.\n",
    "  5. The **`value`** column of the **`items`** data has hashed records. We will look into that and group them accordingly.\n",
    "  6. All 3 datasets have some relationship. We will consider that during the analysis.\n",
    "  7. **`49 815`** items in the **`event`** table do not exist in the **`items`** table. Hence they may be invalid records or old deleted items.\n",
    "  8. **`30`** unique records of the category property in **`items`** table point to non-existence category in the `category_tree` table. This could be a data entry issue or data loss issue. Hence, we will not drop those records or replace them but leave them as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d78ce6",
   "metadata": {
    "id": "93d78ce6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cc49d50",
   "metadata": {
    "id": "2cc49d50"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf3ecf1b",
   "metadata": {
    "id": "cf3ecf1b"
   },
   "source": [
    "### 2.2 Data Cleaning and Preprocessing<a id='dcp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf61e83",
   "metadata": {
    "id": "1bf61e83"
   },
   "source": [
    "<p style=\"text-align:justify\">The preprocessing step (usually an iterative process) is carried out to clean the data based on data quality issues identified. During the data quality assessment, we identified various data quality issues including missing values, incorrect data, inconsistent values, etc.\n",
    "\n",
    "In this task we will perform all the initial data cleaning and preprocessing needed to produce data that will be suitable for our analysis.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d22bf",
   "metadata": {
    "id": "699d22bf"
   },
   "source": [
    "Here, we will handle missing values, inconsistent data types, and other data quality issues in the combined item properties data and the `events.csv` and `category_tree.csv` dataframes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8707337",
   "metadata": {
    "id": "f8707337"
   },
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e16757",
   "metadata": {
    "id": "65e16757"
   },
   "source": [
    "1. **events data**\n",
    "\n",
    "    The missing values in the `transactionid` column indicates that there was no transaction for such cases. Hence we will replace those with `0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1a05c9",
   "metadata": {
    "id": "2b1a05c9"
   },
   "outputs": [],
   "source": [
    "event['transactionid'] = event['transactionid'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db1156",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "76db1156",
    "outputId": "d9ad5553-10fd-4bd3-bd73-fdddf1544484"
   },
   "outputs": [],
   "source": [
    "missing_values(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197b299",
   "metadata": {
    "id": "6197b299"
   },
   "source": [
    "2. **category_tree data**\n",
    "    The missing values in the `parentid` column indicates these are root categories  and do not have a parent in the tree. Replacing them will imply there is a parentid. Hence we will leave it as it is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a0ab5",
   "metadata": {
    "id": "701a0ab5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2315dcb2",
   "metadata": {
    "id": "2315dcb2"
   },
   "source": [
    "#### Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ac901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab9ac901",
    "outputId": "fe126f57-3fcf-4a3e-f761-353f7599840e"
   },
   "outputs": [],
   "source": [
    "event.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e0060f",
   "metadata": {
    "id": "18e0060f"
   },
   "outputs": [],
   "source": [
    "# deleting duplicates\n",
    "\n",
    "event = event.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907399af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "907399af",
    "outputId": "206e637d-a4d6-4b14-c6b4-67031eb89b92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a983485",
   "metadata": {
    "id": "9a983485"
   },
   "source": [
    "> All duplcates are deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4fc1b",
   "metadata": {
    "id": "a1e4fc1b"
   },
   "source": [
    "#### Handling Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a247fc0a",
   "metadata": {
    "id": "a247fc0a"
   },
   "outputs": [],
   "source": [
    "# converting event timestamp to datetime object\n",
    "\n",
    "event['timestamp'] = pd.to_datetime(event['timestamp'], unit='ms').dt.floor('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a824a33",
   "metadata": {
    "id": "3a824a33"
   },
   "outputs": [],
   "source": [
    "# converting event transactionid to int\n",
    "\n",
    "event['transactionid'] = event['transactionid'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0c17b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25f0c17b",
    "outputId": "ce1e3ec2-1527-4971-9df6-63e73f712284"
   },
   "outputs": [],
   "source": [
    "event.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89cc5e10",
   "metadata": {
    "id": "89cc5e10"
   },
   "outputs": [],
   "source": [
    "# converting items timestamp to datetime object\n",
    "\n",
    "items['timestamp'] = pd.to_datetime(items['timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25f9a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a25f9a7",
    "outputId": "dc72dec0-5df2-40e6-e301-363175fe744f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aeafd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c1aeafd8",
    "outputId": "20e0e325-ffd9-47ae-8f19-c61a9bb29c64",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52834f5a",
   "metadata": {
    "id": "52834f5a"
   },
   "source": [
    "**Dropping non-existing itemid from events table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8e8bd7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8e8bd7e",
    "outputId": "0287ac25-9d71-4880-8661-17ad14fb4a23",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 255585 events due to missing itemid\n"
     ]
    }
   ],
   "source": [
    "valid_itemids = set(items['itemid'].unique())\n",
    "\n",
    "valid_events = event[event['itemid'].isin(valid_itemids)]\n",
    "\n",
    "dropped_events = len(event) - len(valid_events)\n",
    "print(f\"Dropped {dropped_events} events due to missing itemid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179d184",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c179d184",
    "outputId": "60a70698-b9a1-43e8-b507-1530f5b0d3c0"
   },
   "outputs": [],
   "source": [
    "itemids_left = set(valid_events['itemid'].unique()) - set(items['itemid'].unique())\n",
    "print(len(itemids_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2609c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fc2609c6",
    "outputId": "2a5aa7bf-d9d7-4318-bf19-59ca666cf682",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b85eb",
   "metadata": {
    "id": "fd7b85eb"
   },
   "source": [
    "> All `itemids` on the event table now do exist on the `item_property` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b08fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f37b08fd",
    "outputId": "08b6b9d1-00af-43d9-cd07-b0e687864bcf"
   },
   "outputs": [],
   "source": [
    "valid_events.shape, items.shape, cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a79334",
   "metadata": {
    "id": "92a79334"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4c9ee0",
   "metadata": {
    "id": "2e4c9ee0"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e27a8ed",
   "metadata": {
    "id": "4e27a8ed"
   },
   "source": [
    "#### Creating DATE and TIME columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38b904",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7a38b904",
    "outputId": "694a705a-8d2c-4f01-fb7b-af2c6259b607",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de2657",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c7de2657",
    "outputId": "29895e25-b952-4dc5-d7cc-5d5442626493",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8803ca",
   "metadata": {
    "id": "4e8803ca"
   },
   "outputs": [],
   "source": [
    "items['date'] = items['timestamp'].dt.date\n",
    "items['month'] = items['timestamp'].dt.month\n",
    "items['time'] = items['timestamp'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d13e70ea",
   "metadata": {
    "id": "d13e70ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Berli\\AppData\\Local\\Temp\\ipykernel_16360\\399897513.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_events['date'] = valid_events['timestamp'].dt.date\n",
      "C:\\Users\\Berli\\AppData\\Local\\Temp\\ipykernel_16360\\399897513.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_events['month'] = valid_events['timestamp'].dt.month\n",
      "C:\\Users\\Berli\\AppData\\Local\\Temp\\ipykernel_16360\\399897513.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_events['time'] = valid_events['timestamp'].dt.time\n"
     ]
    }
   ],
   "source": [
    "valid_events['date'] = valid_events['timestamp'].dt.date\n",
    "valid_events['month'] = valid_events['timestamp'].dt.month\n",
    "valid_events['time'] = valid_events['timestamp'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2a467",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4ae2a467",
    "outputId": "28dbbd4f-6641-45cc-d657-7f281fb0f6b0"
   },
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16d5c87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "f16d5c87",
    "outputId": "8a39966d-6857-4a79-b87b-fea8da9180b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-02 05:02:12</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>6</td>\n",
       "      <td>05:02:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-02 05:50:14</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>6</td>\n",
       "      <td>05:50:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-02 05:12:35</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>6</td>\n",
       "      <td>05:12:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-02 05:02:17</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>6</td>\n",
       "      <td>05:02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-06-02 05:48:06</td>\n",
       "      <td>972639</td>\n",
       "      <td>view</td>\n",
       "      <td>22556</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>6</td>\n",
       "      <td>05:48:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  visitorid event  itemid  transactionid        date  \\\n",
       "0 2015-06-02 05:02:12     257597  view  355908              0  2015-06-02   \n",
       "1 2015-06-02 05:50:14     992329  view  248676              0  2015-06-02   \n",
       "3 2015-06-02 05:12:35     483717  view  253185              0  2015-06-02   \n",
       "4 2015-06-02 05:02:17     951259  view  367447              0  2015-06-02   \n",
       "5 2015-06-02 05:48:06     972639  view   22556              0  2015-06-02   \n",
       "\n",
       "   month      time  \n",
       "0      6  05:02:12  \n",
       "1      6  05:50:14  \n",
       "3      6  05:12:35  \n",
       "4      6  05:02:17  \n",
       "5      6  05:48:06  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dd49d",
   "metadata": {
    "id": "a54dd49d"
   },
   "outputs": [],
   "source": [
    "valid_events_copy = valid_events.copy()\n",
    "items_copy = items.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9be0d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "4d9be0d5",
    "outputId": "29c0bbed-e5af-4de5-8021-797cf6fa7c28"
   },
   "outputs": [],
   "source": [
    "valid_events_copy['year'] = valid_events_copy['timestamp'].dt.year\n",
    "valid_events_copy['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525ef6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2525ef6b",
    "outputId": "ec7893d6-8ed3-4827-efa1-f304b2776a09"
   },
   "outputs": [],
   "source": [
    "valid_events_copy['day'] = valid_events_copy['timestamp'].dt.day\n",
    "valid_events_copy['day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b45bff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "82b45bff",
    "outputId": "7e550edc-a658-419f-b030-103a98e6753e"
   },
   "outputs": [],
   "source": [
    "items_copy['year'] = items_copy['timestamp'].dt.year\n",
    "items_copy['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd088f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "15fd088f",
    "outputId": "d75c9fb2-8ae0-4d8b-bee2-37065f66a070"
   },
   "outputs": [],
   "source": [
    "valid_events_copy['hour'] = valid_events_copy['timestamp'].dt.hour\n",
    "valid_events_copy['hour'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ab2a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "965ab2a1",
    "outputId": "107c708e-d373-40ab-e617-c5467b6cab92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_events_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e676c",
   "metadata": {
    "id": "ad2e676c"
   },
   "source": [
    "> - Both the `event` and `items` data cover the year `2015` only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cd2e8",
   "metadata": {
    "id": "ca1cd2e8"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "019ea80d",
   "metadata": {
    "id": "019ea80d"
   },
   "source": [
    "## 3. Exploratory Data Analysis and Visualization<a id='eda'></a>\n",
    "\n",
    "[Move Up](#mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f241c",
   "metadata": {
    "id": "5c5f241c"
   },
   "source": [
    "Here, we will analyse the data and visualize to answer the questions below:\n",
    "\n",
    "1. What is the overall scale of the dataset (unique users & items)?\n",
    "\n",
    "2. What is the distribution of event types (view, add-to-cart, transaction)?\n",
    "\n",
    "3. What are the most popular items?\n",
    "\n",
    "4. How does item popularity vary across time: month and day?\n",
    "\n",
    "5. How many items are available?\n",
    "\n",
    "6. How active are users (number of interactions per user)?\n",
    "\n",
    "7. How active are items (number of users per item)?\n",
    "\n",
    "8. How do user interactions vary over time of day?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac7c4c",
   "metadata": {
    "id": "beac7c4c"
   },
   "source": [
    "#### 1. Overall distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5036e25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5036e25",
    "outputId": "b6761e05-b972-44f7-85e3-fb9f9ffd057b"
   },
   "outputs": [],
   "source": [
    "n_users = valid_events['visitorid'].nunique()\n",
    "n_items = valid_events['itemid'].nunique()\n",
    "print(f\"Unique Users: {n_users}, Unique Items: {n_items}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56921c1",
   "metadata": {
    "id": "e56921c1"
   },
   "source": [
    "> The dataset contains 1,236,032 unique users and 185,246 unique items, indicating a large-scale recommendation challenge. This highlights the importance of efficient algorithms to handle sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c92ee7",
   "metadata": {
    "id": "c7c92ee7"
   },
   "source": [
    "#### 2. Overall distribution of event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f1138",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "e54f1138",
    "outputId": "2db2ee4d-53eb-4283-fb38-1a8a2a98046d"
   },
   "outputs": [],
   "source": [
    "ax = valid_events['event'].value_counts().plot(kind='bar', figsize=(12,6), edgecolor='black', color='violet')\n",
    "\n",
    "ax.yaxis.set_visible(False)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()),\n",
    "                (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.title(\"Distribution of Events in Dataset\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e526b2",
   "metadata": {
    "id": "f2e526b2"
   },
   "source": [
    "> Views dominate the dataset, followed by add-to-cart and transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d60de7",
   "metadata": {
    "id": "f0d60de7"
   },
   "source": [
    "#### 3. Most popular items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd3596",
   "metadata": {
    "id": "02bd3596"
   },
   "outputs": [],
   "source": [
    "pop_item = valid_events['itemid'].value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04274bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "e04274bf",
    "outputId": "fff96374-9501-4c39-a389-65c35470642d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ax = pop_item.plot(kind='bar', color='violet')\n",
    "\n",
    "plt.title(f\"Top 10 most popular items\")\n",
    "plt.xlabel(\"Item ID\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()),\n",
    "                (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca6497",
   "metadata": {
    "id": "c0ca6497"
   },
   "source": [
    "> The chart shows the top 10 most interacted items. These items dominate user engagement, suggesting strong interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jCvFcnNCsn_D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "id": "jCvFcnNCsn_D",
    "outputId": "6f3cd572-1054-4636-b4ed-501480d35e64"
   },
   "outputs": [],
   "source": [
    "pop_item = valid_events[valid_events['event'] == 'transaction'].value_counts().sort_values(ascending=False).head(10)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax = pop_item.plot(kind='bar', color='violet')\n",
    "\n",
    "\n",
    "\n",
    "plt.title(f\"Top 10 most popular items\")\n",
    "\n",
    "plt.xlabel(\"Item ID\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(p.get_height()),\n",
    "   (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "              ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anClaI74wW1K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anClaI74wW1K",
    "outputId": "ec89a181-eef2-434c-b7fe-a99a3abc5741"
   },
   "outputs": [],
   "source": [
    "n_view = valid_events[valid_events['event'] == 'view'].count()['itemid']\n",
    "#n_addtocart = valid_events[valid_events['event'] == 'addtocart'].count()['itemid']\n",
    "n_transaction = valid_events[valid_events['event'] == 'transaction'].count()['itemid']\n",
    "print(n_view, n_transaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zOaYi4n8wrVJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOaYi4n8wrVJ",
    "outputId": "69b9b49b-0eaa-468a-8aae-a4e16a65f0bb"
   },
   "outputs": [],
   "source": [
    "conversion_rate = (n_transaction / n_view) * 100\n",
    "print(f\"Conversion Rate: {conversion_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c67af8",
   "metadata": {
    "id": "53c67af8"
   },
   "source": [
    "#### 4.  Item popularity over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4beea2",
   "metadata": {
    "id": "bd4beea2"
   },
   "source": [
    "#####  4.1  Item popularity by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8861ec7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "f8861ec7",
    "outputId": "dba6f5d5-3008-4730-fec4-39c461eab1f6"
   },
   "outputs": [],
   "source": [
    "monthly_pop = valid_events.groupby('month')['itemid'].count()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(monthly_pop.index, monthly_pop.values, marker='o', linewidth=2)\n",
    "\n",
    "for x, y in zip(monthly_pop.index, monthly_pop.values):\n",
    "    plt.text(x, y+200, str(y), ha='center', fontsize=9)\n",
    "\n",
    "plt.title(\"Item Popularity Over Months (2015)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.xticks(range(1,13))\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a26b59",
   "metadata": {
    "id": "29a26b59"
   },
   "source": [
    "> Engagement fluctuates across months with clear peaks and dips. Fewer visitors engage with the platform in the month of September\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e4a7f",
   "metadata": {
    "id": "e03e4a7f"
   },
   "source": [
    "##### 4.2  Item popularity by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4d47c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "id": "4cd4d47c",
    "outputId": "f5ab5052-fa49-48a8-b0cc-12bfa9e7ede7"
   },
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "pop_daily = valid_events_copy.groupby('day')['itemid'].count()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(pop_daily.index, pop_daily.values, marker='o', markersize=3, linewidth=1, color= 'grey')\n",
    "\n",
    "\n",
    "peaks, _ = find_peaks(pop_daily.values, distance=5, prominence=500)\n",
    "\n",
    "valleys, _ = find_peaks(-pop_daily.values, distance=5, prominence=500)\n",
    "\n",
    "global_min_idx = pop_daily.idxmin()\n",
    "\n",
    "if pop_daily.index.get_loc(global_min_idx) not in valleys:\n",
    "    valleys = list(valleys) + [pop_daily.index.get_loc(global_min_idx)]\n",
    "\n",
    "\n",
    "for i in peaks:\n",
    "    plt.annotate(f\"{pop_daily.values[i]}\",\n",
    "                 xy=(pop_daily.index[i], pop_daily.values[i]),\n",
    "                 xytext=(pop_daily.index[i], pop_daily.values[i] + 500),\n",
    "                 arrowprops=dict(arrowstyle=\"->\", color=\"green\"),\n",
    "                 ha='center', fontsize=8, color=\"green\")\n",
    "\n",
    "\n",
    "for i in valleys:\n",
    "    plt.annotate(f\"{pop_daily.values[i]}\",\n",
    "                 xy=(pop_daily.index[i], pop_daily.values[i]),\n",
    "                 xytext=(pop_daily.index[i], pop_daily.values[i] + 500),\n",
    "                 arrowprops=dict(arrowstyle=\"->\", color=\"red\"),\n",
    "                 ha='center', fontsize=8, color=\"red\")\n",
    "\n",
    "\n",
    "plt.title(\"Daily Popularity of Items (2015)\")\n",
    "plt.xlabel(\"Date(day)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf54425",
   "metadata": {
    "id": "dbf54425"
   },
   "source": [
    "> - Daily trends reveal strong peaks and troughs, useful for modeling temporal effects in recommendations.\n",
    "> - The are moderately  high interactions late mornings through to early afternoons.\n",
    "> - From 4pm to late evenings, interactions reduce drastically.\n",
    "> - Interactions are on the minimum at dawn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b22baa2",
   "metadata": {
    "id": "6b22baa2"
   },
   "source": [
    "#### 5.  Items available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df2f09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07df2f09",
    "outputId": "0a477ca5-ea6c-43f8-c602-231962dd67b6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(items[(items['property'] == 'available') & (items['value'] == '1')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f3fa4",
   "metadata": {
    "id": "1e3f3fa4"
   },
   "source": [
    "> `640553` items have availabily value of `1`, indicating their avaialability on the e-commerce platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24662a6",
   "metadata": {
    "id": "e24662a6"
   },
   "source": [
    "#### 6.  Most active users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd769e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "35fd769e",
    "outputId": "5ef0ce96-f8f3-4a9e-8cb1-6869e5a68e8e"
   },
   "outputs": [],
   "source": [
    "active_users = valid_events['visitorid'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "bars = plt.bar(active_users.index.astype(str), active_users.values, color='pink')\n",
    "\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_x() + bar.get_width()/2,\n",
    "             bar.get_height(),\n",
    "             str(bar.get_height()),\n",
    "             ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 10 Most Active Users\")\n",
    "plt.xlabel(\"User ID\")\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd376ef",
   "metadata": {
    "id": "0fd376ef"
   },
   "source": [
    "#### 7.  Items with most interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd219ee6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "dd219ee6",
    "outputId": "cdb360f9-35fc-4284-fb38-e58cd37d876e"
   },
   "outputs": [],
   "source": [
    "item_activity = valid_events.groupby('itemid')['visitorid'].count()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(item_activity, bins=50, log=True, color='grey')\n",
    "plt.title(\"Distribution of Item Activity\")\n",
    "plt.xlabel(\"Number of Users per Item\")\n",
    "plt.ylabel(\"Item Count (log scale)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc400ec",
   "metadata": {
    "id": "bdc400ec"
   },
   "source": [
    "#### 8.  User interactions over time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4516afc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "a4516afc",
    "outputId": "1a73e1bb-918d-4e8d-fcbf-5580002acf33"
   },
   "outputs": [],
   "source": [
    "hourly_activity = valid_events_copy.groupby('hour')['itemid'].count()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(hourly_activity.index, hourly_activity.values, marker='o')\n",
    "\n",
    "\n",
    "peaks, _ = find_peaks(hourly_activity.values, distance=1, prominence=5)\n",
    "valleys, _ = find_peaks(-hourly_activity.values, distance=1, prominence=5)\n",
    "\n",
    "# Always include global max and min\n",
    "global_max_idx = hourly_activity.idxmax()\n",
    "global_min_idx = hourly_activity.idxmin()\n",
    "\n",
    "if hourly_activity.index.get_loc(global_max_idx) not in peaks:\n",
    "    peaks = list(peaks) + [hourly_activity.index.get_loc(global_max_idx)]\n",
    "if hourly_activity.index.get_loc(global_min_idx) not in valleys:\n",
    "    valleys = list(valleys) + [hourly_activity.index.get_loc(global_min_idx)]\n",
    "\n",
    "# Annotate peaks\n",
    "for i in peaks:\n",
    "    plt.scatter(hourly_activity.index[i], hourly_activity.values[i], color=\"green\", s=50, zorder=3)\n",
    "    plt.text(hourly_activity.index[i], hourly_activity.values[i] + 3,\n",
    "             f\"{hourly_activity.values[i]}\", ha='center', fontsize=8, color=\"green\")\n",
    "\n",
    "# Annotate valleys\n",
    "for i in valleys:\n",
    "    plt.scatter(hourly_activity.index[i], hourly_activity.values[i], color=\"red\", s=50, zorder=3)\n",
    "    plt.text(hourly_activity.index[i], hourly_activity.values[i] + 3,\n",
    "             f\"{hourly_activity.values[i]}\", ha='center', fontsize=8, color=\"red\")\n",
    "\n",
    "plt.title(\"User Activity by Hour of Day\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad918d",
   "metadata": {
    "id": "b6ad918d"
   },
   "source": [
    "> User activity follows a daily cycle, peaking in the evening. This can inform time-aware recommendation models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd013924",
   "metadata": {
    "id": "cd013924"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "061accff",
   "metadata": {
    "id": "061accff"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3c6f889",
   "metadata": {
    "id": "e3c6f889"
   },
   "source": [
    "## 5. Modeling and evaluation<a id='dm'></a>\n",
    "\n",
    "[Move Up](#mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed5aa7",
   "metadata": {
    "id": "9bed5aa7"
   },
   "source": [
    "To remind ourselves, we stated earlier as one of the objectives to build a model that is able to recommend items to users. Based on the methodology framework we saw at the beginning, we know that our problem is a prediction problem. We also highlighted that, we will have to build multiple models and then finally select the best one based on certain evaluation metrics.\n",
    "\n",
    "Therefore, to complete this task we will go through the various machine learning steps which includes;\n",
    "\n",
    "Data Understanding\n",
    "Feature Engineering\n",
    "Splitting Dataset\n",
    "Algorithm Evaluation\n",
    "Parameter Tuning\n",
    "Final Model\n",
    "Model Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2d03",
   "metadata": {
    "id": "9e8a2d03"
   },
   "source": [
    "### 5.1 Data Understanding<a id='du'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683cfa1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6683cfa1",
    "outputId": "7d1080a2-a9ef-4baa-8468-787f0d0e75a3"
   },
   "outputs": [],
   "source": [
    "# Shape of dataset\n",
    "print(f\"Rows(events): {valid_events.shape[0]}, Columns(events): {valid_events.shape[1]}\")\n",
    "\n",
    "# Info summary\n",
    "print(valid_events.info())\n",
    "\n",
    "# Missing values\n",
    "print(valid_events.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rhNQXDqA_vG7",
   "metadata": {
    "id": "rhNQXDqA_vG7"
   },
   "source": [
    "> items and events table have `itemid` in common, hence we will merge them before we proceed with our model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KG13xROEAwS4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "KG13xROEAwS4",
    "outputId": "9daaf96a-1782-4be8-f842-1b38b0bda28c"
   },
   "outputs": [],
   "source": [
    "valid_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nKKQT2E2auNX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nKKQT2E2auNX",
    "outputId": "182dd8b1-ca75-42e3-9f29-aaa7031f3562"
   },
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0kSVCdDGHs3m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kSVCdDGHs3m",
    "outputId": "ca052fdf-c1b5-40b5-82c0-c532f333d422"
   },
   "outputs": [],
   "source": [
    "items['property'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nzaXmB14ayS4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nzaXmB14ayS4",
    "outputId": "3163cd9a-5e47-4dc6-af26-f7f74f21a284"
   },
   "outputs": [],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e8658",
   "metadata": {
    "id": "9d9e8658"
   },
   "source": [
    "### 5.2 Feature Engineering & Selection (implicit strength) <a id='fe'></a>\n",
    "\n",
    "Based on the outcome from data understanding, we will engineer new features and determine which features are needed for building our ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "_KLChPapWuXt",
   "metadata": {
    "id": "_KLChPapWuXt"
   },
   "outputs": [],
   "source": [
    "selected_items = items[['itemid', 'property', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "UKdFEBoYbU_s",
   "metadata": {
    "id": "UKdFEBoYbU_s"
   },
   "outputs": [],
   "source": [
    "selected_items['categoryid'] = pd.to_numeric(\n",
    "    selected_items.loc[selected_items['property'] == 'categoryid', 'value'],\n",
    "    errors='coerce'\n",
    ").fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "p3N1GmQVbi5p",
   "metadata": {
    "id": "p3N1GmQVbi5p"
   },
   "outputs": [],
   "source": [
    "selected_items['available'] = pd.to_numeric(\n",
    "    selected_items.loc[selected_items['property'] == 'available', 'value'],\n",
    "    errors='coerce'\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "TXQ9t9LiIM5W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TXQ9t9LiIM5W",
    "outputId": "4165065f-9d6a-4784-bb35-6b5f617e3b27"
   },
   "outputs": [],
   "source": [
    "selected_items = selected_items[['itemid', 'categoryid', 'available']]\n",
    "# selected_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb338b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_items.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "kHWKe7pMQtHy",
   "metadata": {
    "id": "kHWKe7pMQtHy"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 19.3 MiB for an array with shape (20275902,) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_item_properties \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategoryid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Berli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Berli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:883\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 883\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    886\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    887\u001b[0m )\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\Users\\Berli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1133\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1130\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1131\u001b[0m     )\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Berli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1105\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_join_indexers\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]]:\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Berli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1713\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1707\u001b[0m lkey, rkey \u001b[38;5;241m=\u001b[39m _get_join_keys(llab, rlab, \u001b[38;5;28mtuple\u001b[39m(shape), sort)\n\u001b[0;32m   1709\u001b[0m \u001b[38;5;66;03m# factorize keys to a dense i8 space\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# `count` is the num. of unique keys\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# set(lkey) | set(rkey) == range(count)\u001b[39;00m\n\u001b[1;32m-> 1713\u001b[0m lkey, rkey, count \u001b[38;5;241m=\u001b[39m \u001b[43m_factorize_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;66;03m# preserve left frame order if how == 'left' and sort == False\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Berli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2513\u001b[0m, in \u001b[0;36m_factorize_keys\u001b[1;34m(lk, rk, sort, how)\u001b[0m\n\u001b[0;32m   2511\u001b[0m lmask \u001b[38;5;241m=\u001b[39m llab \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2512\u001b[0m lany \u001b[38;5;241m=\u001b[39m lmask\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m-> 2513\u001b[0m rmask \u001b[38;5;241m=\u001b[39m \u001b[43mrlab\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m   2514\u001b[0m rany \u001b[38;5;241m=\u001b[39m rmask\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m   2516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lany \u001b[38;5;129;01mor\u001b[39;00m rany:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 19.3 MiB for an array with shape (20275902,) and data type bool"
     ]
    }
   ],
   "source": [
    "all_item_properties = pd.merge(cat, selected_items, on='categoryid', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RG8RAiw_hcZd",
   "metadata": {
    "id": "RG8RAiw_hcZd"
   },
   "outputs": [],
   "source": [
    "final_df = pd.merge(valid_events, all_item_properties, on='itemid', how='left')\n",
    "\n",
    "# print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb04eb",
   "metadata": {
    "id": "6efb04eb"
   },
   "source": [
    "### 5.3 Splitting Dataset (time-based) <a id='sd'></a>\n",
    "\n",
    "\n",
    "It is a good idea to use a test hold-out set. This is a sample of the data that we hold back from our analysis and modeling. We use it right at the end of our project to evaluate the performance of our final model. It is a smoke test that we can use to see if we messed up and to give us confidence on models performance on unseen data. We will use 80% of the dataset for modeling and hold back 20% for validation.\n",
    "\n",
    "We will begin by importing the needed libraries for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88d3a8",
   "metadata": {
    "id": "dd88d3a8"
   },
   "source": [
    "### 5.4 Modeling (3 practical baselines) <a id='sd'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a647a8d8",
   "metadata": {
    "id": "a647a8d8"
   },
   "source": [
    "#### 1) Popularity (global) <a id='pg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59612de5",
   "metadata": {
    "id": "59612de5"
   },
   "outputs": [],
   "source": [
    "# Recommend most popular items from train (by strength)\n",
    "pop_scores = train_ui.groupby('itemid')['strength'].sum().sort_values(ascending=False)\n",
    "popular_items = pop_scores.index.values  # ranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cad064",
   "metadata": {
    "id": "36cad064"
   },
   "source": [
    "#### 2) Item-Item Cosine (TF-IDF-ish weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff7769",
   "metadata": {
    "id": "75ff7769"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "user_encoder = {u: i for i, u in enumerate(valid_events['visitorid'].unique())}\n",
    "item_encoder = {i: j for j, i in enumerate(valid_events['itemid'].unique())}\n",
    "item_decoder = {j: i for i, j in item_encoder.items()}\n",
    "\n",
    "row = valid_events['visitorid'].map(user_encoder)\n",
    "col = valid_events['itemid'].map(item_encoder)\n",
    "data = [1] * len(valid_events)  # implicit feedback (1 per interaction)\n",
    "\n",
    "user_item_matrix = csr_matrix((data, (row, col)), shape=(len(user_encoder), len(item_encoder)))\n",
    "\n",
    "item_user_matrix = user_item_matrix.T\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model_knn.fit(item_user_matrix)\n",
    "\n",
    "# Function to get similar items\n",
    "def get_similar_items(item_id, n_neighbors=6):\n",
    "    if item_id not in item_encoder:\n",
    "        return f\"Item {item_id} not found in data.\"\n",
    "\n",
    "    item_idx = item_encoder[item_id]\n",
    "    distances, indices = model_knn.kneighbors(item_user_matrix[item_idx], n_neighbors=n_neighbors)\n",
    "\n",
    "    similar_items = [(item_decoder[i], 1 - distances.flatten()[j])\n",
    "                     for j, i in enumerate(indices.flatten()) if i != item_idx]\n",
    "\n",
    "    return sorted(similar_items, key=lambda x: -x[1])\n",
    "\n",
    "# Example usage\n",
    "sample_item = list(item_encoder.keys())[100]\n",
    "print(f\"Items similar to {sample_item}:\")\n",
    "print(get_similar_items(sample_item, n_neighbors=6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d2d3a",
   "metadata": {
    "id": "0b4d2d3a"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Encode IDs\n",
    "user_ids = {u: i for i, u in enumerate(valid_events['visitorid'].unique())}\n",
    "item_ids = {i: j for j, i in enumerate(valid_events['itemid'].unique())}\n",
    "\n",
    "valid_events['user_idx'] = valid_events['visitorid'].map(user_ids)\n",
    "valid_events['item_idx'] = valid_events['itemid'].map(item_ids)\n",
    "\n",
    "# Step 2: Build sparse user-item matrix\n",
    "rows = valid_events['item_idx']\n",
    "cols = valid_events['user_idx']\n",
    "data = [1] * len(valid_events)   # binary interaction\n",
    "item_user_matrix = csr_matrix((data, (rows, cols)),\n",
    "                              shape=(len(item_ids), len(user_ids)))\n",
    "\n",
    "# Step 3: Apply TF-IDF weighting\n",
    "tfidf = TfidfTransformer()\n",
    "item_user_tfidf = tfidf.fit_transform(item_user_matrix)\n",
    "\n",
    "# Step 4: Compute item-item similarity (sparse safe)\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\", n_neighbors=20, n_jobs=-1)\n",
    "knn.fit(item_user_tfidf)\n",
    "\n",
    "def get_similar_items(item_raw_id, top_n=10):\n",
    "    if item_raw_id not in item_ids:\n",
    "        return []\n",
    "    idx = item_ids[item_raw_id]\n",
    "    distances, indices = knn.kneighbors(item_user_tfidf[idx], n_neighbors=top_n+1)\n",
    "    similar = [(list(item_ids.keys())[list(item_ids.values()).index(i)], 1-d)\n",
    "               for i, d in zip(indices.flatten()[1:], distances.flatten()[1:])]\n",
    "    return similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e6be4",
   "metadata": {
    "id": "606e6be4"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# # Build user–item matrix for train\n",
    "u_ids = {u:i for i,u in enumerate(train_ui['visitorid'].unique())}\n",
    "i_ids = {it:i for i,it in enumerate(train_ui['itemid'].unique())}\n",
    "ru = train_ui['visitorid'].map(u_ids)\n",
    "ri = train_ui['itemid'].map(i_ids)\n",
    "R = csr_matrix((train_ui['strength'].values, (ru, ri)), shape=(len(u_ids), len(i_ids)))\n",
    "\n",
    "# # Item similarity matrix (cosine)\n",
    "# S = cosine_similarity(R.T)  # items x items\n",
    "\n",
    "# # Fast top-K per item (indices)\n",
    "# topk = 100\n",
    "# sim_idx = np.argpartition(-S, kth=range(1,topk+1), axis=1)[:, :topk]  # approximate top-k\n",
    "\n",
    "\n",
    "\n",
    "# Fit NearestNeighbors with cosine distance\n",
    "knn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\", n_neighbors=50, n_jobs=-1)\n",
    "knn.fit(R.T)\n",
    "\n",
    "# Get Top-50 neighbors for each item\n",
    "distances, indices = knn.kneighbors(R.T, return_distance=True)\n",
    "\n",
    "print(f\"indices shape: {indices.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4bb864",
   "metadata": {
    "id": "0d4bb864"
   },
   "source": [
    "#### 3) Latent Factors (TruncatedSVD ≈ MF for implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06464b5",
   "metadata": {
    "id": "f06464b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "k = 64\n",
    "svd = TruncatedSVD(n_components=k, random_state=42)\n",
    "Vt = svd.fit_transform(R.T)\n",
    "U  = (R @ Vt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9593ad3",
   "metadata": {
    "id": "e9593ad3"
   },
   "source": [
    "> We establish three strong baselines: Popularity, Item-Item CF, and SVD latent factors. These cover non-personalized and personalized recommenders for implicit data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb432f",
   "metadata": {
    "id": "e3cb432f"
   },
   "source": [
    "### 3.3 Algorithm Evaluation (Precision@K, Recall@K) <a id='sd'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b390a",
   "metadata": {
    "id": "c47b390a"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def to_user_items(df):\n",
    "    g = defaultdict(set)\n",
    "    for u, it in df[['visitorid','itemid']].itertuples(index=False):\n",
    "        g[u].add(it)\n",
    "    return g\n",
    "\n",
    "train_pos = to_user_items(train_ui)\n",
    "test_pos  = to_user_items(test_ui)\n",
    "\n",
    "all_items = np.array(list(i_ids.keys()))\n",
    "item_inv  = {it:i for i,it in enumerate(i_ids.keys())}  # itemid -> col index (train matrix)\n",
    "\n",
    "def recommend_pop(u, K=10):\n",
    "    return popular_items[:K]\n",
    "\n",
    "def recommend_cf(u, K=10):\n",
    "    # score by summing similarities to items user had in train\n",
    "    if u not in train_pos: return popular_items[:K]\n",
    "    seen = [item_inv[it] for it in train_pos[u] if it in item_inv]\n",
    "    if not seen: return popular_items[:K]\n",
    "    scores = S[:, seen].sum(axis=1)  # aggregate similarity\n",
    "    # filter seen\n",
    "    scores[seen] = -np.inf\n",
    "    top = np.argpartition(-scores, K)[:K]\n",
    "    return np.array(list(i_ids.keys()))[top]\n",
    "\n",
    "def recommend_svd(u, K=10):\n",
    "    if u not in u_ids: return popular_items[:K]\n",
    "    urow = U[u_ids[u]]            # user vector\n",
    "    scores = Vt @ urow            # item scores\n",
    "    seen  = [item_inv[it] for it in train_pos.get(u, []) if it in item_inv]\n",
    "    if seen:\n",
    "        scores[seen] = -np.inf\n",
    "    top = np.argpartition(-scores, K)[:K]\n",
    "    return np.array(list(i_ids.keys()))[top]\n",
    "\n",
    "def precision_recall_at_k(recommender, K=10, users=None):\n",
    "    if users is None:\n",
    "        users = list(set(test_pos.keys()) & set(train_pos.keys()))\n",
    "    hits = 0; total_pred = 0; total_true = 0\n",
    "    for u in users:\n",
    "        true = test_pos[u]\n",
    "        recs = recommender(u, K=K)\n",
    "        hits += len(set(recs) & true)\n",
    "        total_pred += K\n",
    "        total_true += len(true)\n",
    "    precision = hits / total_pred if total_pred else 0\n",
    "    recall = hits / total_true if total_true else 0\n",
    "    return precision, recall\n",
    "\n",
    "for name, f in [('Popularity', recommend_pop), ('ItemCF', recommend_cf), ('SVD', recommend_svd)]:\n",
    "    p, r = precision_recall_at_k(f, K=10)\n",
    "    print(f\"{name} @10 → Precision: {p:.4f} | Recall: {r:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110a5004",
   "metadata": {
    "id": "110a5004"
   },
   "source": [
    "> - Popularity gives a strong but generic baseline.\n",
    "\n",
    "> - Item-Item CF usually improves personalization when users have prior interactions.\n",
    "\n",
    "> - SVD often wins if you have enough data; tune k and regularization (we used default SVD; implicit ALS can be even better)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba371ad1",
   "metadata": {
    "id": "ba371ad1"
   },
   "source": [
    "### 5.3 Confidence Intervals & Hypothesis Test (bootstrap on user-level Precision@K) <a id='ci'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f150bb",
   "metadata": {
    "id": "42f150bb"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def user_precision(recommender, K=10):\n",
    "    vals = []\n",
    "    users = list(set(test_pos.keys()) & set(train_pos.keys()))\n",
    "    for u in users:\n",
    "        true = test_pos[u]\n",
    "        recs = recommender(u, K=K)\n",
    "        vals.append(len(set(recs) & true)/K)\n",
    "    return np.array(vals)\n",
    "\n",
    "pop_p = user_precision(recommend_pop, K=10)\n",
    "svd_p = user_precision(recommend_svd, K=10)\n",
    "\n",
    "def bootstrap_ci(x, B=1000, alpha=0.05):\n",
    "    means = []\n",
    "    n = len(x)\n",
    "    for _ in range(B):\n",
    "        sample = x[np.random.randint(0, n, n)]\n",
    "        means.append(sample.mean())\n",
    "    lo, hi = np.percentile(means, [100*alpha/2, 100*(1-alpha/2)])\n",
    "    return lo, hi\n",
    "\n",
    "pop_ci = bootstrap_ci(pop_p)\n",
    "svd_ci = bootstrap_ci(svd_p)\n",
    "print(\"Precision@10 CI (Popularity):\", pop_ci)\n",
    "print(\"Precision@10 CI (SVD):\", svd_ci)\n",
    "\n",
    "# Hypothesis: SVD precision mean > Pop precision mean (paired bootstrap)\n",
    "diffs = []\n",
    "for _ in range(1000):\n",
    "    idx = np.random.randint(0, len(pop_p), len(pop_p))\n",
    "    diffs.append((svd_p[idx] - pop_p[idx]).mean())\n",
    "p_value = (np.array(diffs) <= 0).mean()  # one-sided\n",
    "print(f\"Paired bootstrap p-value (SVD > Pop): {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec6f48",
   "metadata": {
    "id": "48ec6f48"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c49af0",
   "metadata": {
    "id": "01c49af0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ceaced6",
   "metadata": {
    "id": "2ceaced6"
   },
   "source": [
    "### 5.5 Hyperparameter Tuning<a id='pt'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e447e",
   "metadata": {
    "id": "e75e447e"
   },
   "outputs": [],
   "source": [
    "ks = [32, 64, 96, 128]\n",
    "results = []\n",
    "for k in ks:\n",
    "    svd = TruncatedSVD(n_components=k, random_state=42)\n",
    "    Vt_k = svd.fit_transform(R.T)\n",
    "    U_k  = (R @ Vt_k)\n",
    "    def recommend_svd_k(u, K=10, U_k=U_k, Vt_k=Vt_k):\n",
    "        if u not in u_ids: return popular_items[:K]\n",
    "        scores = Vt_k @ U_k[u_ids[u]]\n",
    "        seen  = [item_inv[it] for it in train_pos.get(u, []) if it in item_inv]\n",
    "        if seen: scores[seen] = -np.inf\n",
    "        top = np.argpartition(-scores, K)[:K]\n",
    "        return np.array(list(i_ids.keys()))[top]\n",
    "    p, r = precision_recall_at_k(recommend_svd_k, K=10)\n",
    "    results.append((k, p, r))\n",
    "\n",
    "pd.DataFrame(results, columns=['k','precision@10','recall@10']).sort_values('precision@10', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bfe48d",
   "metadata": {
    "id": "29bfe48d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bc751ee",
   "metadata": {
    "id": "0bc751ee"
   },
   "source": [
    "### 5.6 Finalizing Model<a id='fm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9963aee2",
   "metadata": {
    "id": "9963aee2"
   },
   "outputs": [],
   "source": [
    "# Refit chosen model on ALL filtered interactions (train + test period combined)\n",
    "all_e = ef.copy()\n",
    "all_ui = all_e.groupby(['visitorid','itemid'])['strength'].sum().reset_index()\n",
    "\n",
    "u_all = {u:i for i,u in enumerate(all_ui['visitorid'].unique())}\n",
    "i_all = {it:i for i,it in enumerate(all_ui['itemid'].unique())}\n",
    "Ru = all_ui['visitorid'].map(u_all); Ri = all_ui['itemid'].map(i_all)\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "R_all = csr_matrix((all_ui['strength'].values, (Ru, Ri)), shape=(len(u_all), len(i_all)))\n",
    "\n",
    "# Final SVD\n",
    "best_k = 64\n",
    "final_svd = TruncatedSVD(n_components=best_k, random_state=42)\n",
    "Vt_final = final_svd.fit_transform(R_all.T)\n",
    "\n",
    "import joblib\n",
    "joblib.dump({\n",
    "    'u_index': u_all,\n",
    "    'i_index': i_all,\n",
    "    'Vt': Vt_final,\n",
    "    'model': final_svd\n",
    "}, '../App/final_recommender_svd.pkl')\n",
    "print(\"Saved final model to final_recommender_svd.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5d212",
   "metadata": {
    "id": "1ef5d212"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c4bb1cb",
   "metadata": {
    "id": "5c4bb1cb"
   },
   "source": [
    "### 5.7 Model Understanding<a id='mdu'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e3f93",
   "metadata": {
    "id": "972e3f93"
   },
   "outputs": [],
   "source": [
    "# Inspect nearest neighbors for a sample item (by cosine in factor space)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sample_item = next(iter(i_all.keys()))\n",
    "sample_vec = Vt_final[i_all[sample_item]].reshape(1, -1)\n",
    "sims = cosine_similarity(sample_vec, Vt_final).ravel()\n",
    "top_idx = np.argpartition(-sims, 11)[:11]  # include itself\n",
    "neighbors = [list(i_all.keys())[i] for i in top_idx if list(i_all.keys())[i] != sample_item]\n",
    "neighbors[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820657b8",
   "metadata": {
    "id": "820657b8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5a0cfbb",
   "metadata": {
    "id": "c5a0cfbb"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "156a13c7",
   "metadata": {
    "id": "156a13c7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50ac2dd3",
   "metadata": {
    "id": "50ac2dd3"
   },
   "source": [
    "### 6. Conclusion and Recommendation<a id='cr'></a>\n",
    "\n",
    "[Move Up](#mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a3124",
   "metadata": {
    "id": "1c6a3124"
   },
   "source": [
    "This analysis of TransBorder Freight Data, spanning from 2020 to 2024, has provided valuable insights into the dynamics of trade between the United States, Canada, and Mexico. Leveraging the CRISP-DM methodology, we have cleaned, preprocessed, and explored the dataset to uncover key patterns, potential inefficiencies, and areas for improvement.\n",
    "\n",
    "**Key Insights from Exploratory Data Analysis (EDA)**\n",
    "1. Trade Type Dynamics:\n",
    "\n",
    "    - While the number of export shipments is higher, the total value and weight of import shipments significantly exceed exports. This suggests that imported goods are generally of higher individual value and greater physical volume, potentially comprising raw materials or heavier manufactured goods.\n",
    "     ** **\n",
    "\n",
    "2. Dominance of Transportation Modes:\n",
    "\n",
    "    - Trucking is the undisputed leader in terms of the number of shipments and total economic value for transborder freight. Its flexibility and extensive network make it the primary choice for a wide range of goods.\n",
    "\n",
    "    - For total physical weight, Vessel and Pipeline transportation are paramount, indicating their critical role in moving bulk commodities (e.g., oil, gas, minerals) where volume is the primary factor.\n",
    "\n",
    "    - Rail transportation holds a strong second position in both value and weight, particularly for Canadian trade.\n",
    "     ** **\n",
    "\n",
    "3. Geographical Hotspots and Trade Corridors:\n",
    "\n",
    "    - Texas (TX) is the most significant U.S. state for transborder freight in terms of both value and weight among the known states, serving as a major gateway to Mexico.\n",
    "\n",
    "    - Ontario (XO) is the leading Canadian province by value, reflecting its industrial ties, while Alberta (XA) dominates by weight, largely due to energy exports.\n",
    "\n",
    "    - Mexican trade is concentrated in states bordering the U.S., though a significant portion of Mexican state data is unclassified (\"XX\").\n",
    "\n",
    "    - Data Limitation: A substantial portion of geographical data (U.S. States, Mexican States, Canadian Provinces) is classified as \"UNKNOWN\" or generic codes, limiting granular regional analysis.\n",
    "     ** **\n",
    "\n",
    "4. Temporal Trends and Economic Resilience:\n",
    "\n",
    "    - The data clearly shows a sharp decline in freight value and weight in early to mid-2020, directly correlating with the onset of the COVID-19 pandemic.\n",
    "\n",
    "    - Following this initial disruption, there has been a strong and sustained recovery and growth in transborder freight activity through 2021, 2022, and 2023, reaching levels higher than pre-pandemic. This demonstrates the resilience of the North American supply chain.\n",
    "\n",
    "    - Specific monthly patterns by mode indicate that while overall trends follow economic cycles, individual modes might have unique seasonal fluctuations.\n",
    "     ** **\n",
    "\n",
    "5. Commodity Flow:\n",
    "\n",
    "    - Vehicles (87), Mineral Fuels (27), and Machinery (84, 85) are the highest-value commodities, reflecting the importance of manufacturing and energy trade.\n",
    "\n",
    "    - Mineral Fuels (27), Salt/Sulfur/Earths/Stone (25), and Wood (44) dominate in terms of physical weight, highlighting the movement of raw materials and bulk goods.\n",
    "\n",
    "    - There's a clear distinction: high-value manufactured goods (vehicles, machinery) drive value, while bulk commodities (fuels, minerals, wood) drive weight.\n",
    "     ** **\n",
    "\n",
    "6. Freight Charge Dynamics:\n",
    "\n",
    "    - Air and \"Other\" modes have the highest average freight charges per kilogram, which is expected for expedited or specialized services.\n",
    "\n",
    "    - Pipeline and Rail are the most cost-efficient modes per kilogram, reinforcing their role in bulk transport.\n",
    "\n",
    "    - The relationship between freight charges and value/weight can be complex; further investigation is needed to pinpoint specific inefficiencies beyond these high-level averages.\n",
    "\n",
    "**Recommendations**\n",
    "\n",
    "Based on these insights, here are actionable recommendations to enhance the performance, sustainability, and safety of transborder transportation systems:\n",
    "\n",
    "\n",
    "1. Optimize Trucking Operations:\n",
    "\n",
    "    - Recommendation: Given trucking's overwhelming dominance in shipment count and value, focus on optimizing truck routes, reducing border wait times, and improving road infrastructure at key border crossings (e.g., Texas-Mexico, Michigan-Ontario).\n",
    "\n",
    "    - Why: Even small improvements in efficiency for trucking will yield significant overall benefits due to its sheer volume.\n",
    "\n",
    "    - Impact: Reduced transit times, lower operational costs for businesses, decreased congestion, and improved throughput.\n",
    "    ** **\n",
    "\n",
    "2. Leverage Rail and Pipeline for Bulk Efficiency:\n",
    "\n",
    "    - Recommendation: Encourage and invest in expanding rail and pipeline capacity, especially for high-weight commodities like mineral fuels, metals, and agricultural products, particularly for trade with Canada (Alberta's weight dominance).\n",
    "\n",
    "    - Why: These modes offer superior cost-efficiency for bulk transport and can alleviate road congestion.\n",
    "\n",
    "    - Impact: Lower per-unit shipping costs for bulk goods, reduced environmental footprint compared to trucking for heavy loads, and increased capacity for high-volume trade.\n",
    "    ** **\n",
    "\n",
    "3. Address Data Gaps for Granular Analysis:\n",
    "\n",
    "    - Recommendation: Implement stricter data collection protocols to minimize \"UNKNOWN\" or generic codes for U.S. States, Mexican States, and Canadian Provinces, and ensure SHIPWT data is consistently recorded for all Mexican shipments.\n",
    "\n",
    "    - Why: More complete geographical and weight data would enable more precise routing optimization, infrastructure planning, and a deeper understanding of specific trade corridors and their challenges.\n",
    "\n",
    "    - Impact: Improved data-driven decision-making, more targeted policy interventions, and better resource allocation.  \n",
    "    ** **\n",
    "\n",
    "4. Monitor Economic Resilience and Adaptability:\n",
    "\n",
    "    - Recommendation: Continue to monitor temporal trends closely, especially in light of global economic shifts or unforeseen events. Develop contingency plans based on the observed resilience and recovery patterns post-COVID-19.\n",
    "\n",
    "    - Why: Understanding the system's response to past disruptions can inform strategies for future crises, ensuring supply chain stability.\n",
    "\n",
    "    - Impact: Enhanced supply chain resilience, quicker recovery from disruptions, and minimized economic impact during crises.\n",
    "     ** **\n",
    "\n",
    "5. Investigate High-Cost Freight Segments:\n",
    "\n",
    "    - Recommendation: Conduct deeper analysis into the specific factors contributing to high freight charges per value/weight for \"Pipeline,\" \"Vessel,\" \"Air,\" and \"Other\" modes. This might involve looking at specific commodities, distances, or specialized handling requirements.\n",
    "\n",
    "    - Why: Identifying the root causes of higher costs can reveal opportunities for negotiation, alternative logistics solutions, or technological improvements.\n",
    "\n",
    "    - Impact: Improved cost-efficiency for high-value/specialized freight, potential for innovation in logistics services.\n",
    "     ** **\n",
    "\n",
    "6. Future Data Collection for Sustainability and Safety:\n",
    "\n",
    "    - Recommendation: To address the \"Environmental Impact\" and \"Safety and Risk Assessment\" objectives fully, future data collection should include metrics such as:\n",
    "\n",
    "        - Emissions data: Fuel consumption per mode, carbon footprint.\n",
    "\n",
    "        - Safety incident data: Number of accidents, causes, fatalities, injuries by mode and route.\n",
    "\n",
    "        - Delay/Congestion data: Average transit times, border wait times, and frequency of delays.\n",
    "\n",
    "    - Why: Direct data on these aspects is critical for developing targeted strategies for sustainability and safety improvements.\n",
    "\n",
    "    - Impact: Enables data-driven policies for reducing environmental impact (e.g., promoting greener modes, optimizing fuel use) and enhancing safety protocols, leading to fewer incidents and a more secure transportation network.\n",
    "\n",
    "This comprehensive analysis provides a strong foundation for stakeholders to make informed decisions and implement strategies that enhance the efficiency, sustainability, and safety of North American transborder freight operations.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
